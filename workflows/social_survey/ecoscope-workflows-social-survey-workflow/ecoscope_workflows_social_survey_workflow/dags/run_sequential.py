# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details
import json
import os

from ecoscope_workflows_core.tasks.config import (
    set_workflow_details as set_workflow_details,
)
from ecoscope_workflows_core.tasks.filter import set_time_range as set_time_range
from ecoscope_workflows_core.tasks.groupby import set_groupers as set_groupers
from ecoscope_workflows_core.tasks.io import persist_text as persist_text
from ecoscope_workflows_core.tasks.io import set_er_connection as set_er_connection
from ecoscope_workflows_core.tasks.results import gather_dashboard as gather_dashboard
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_skipped as any_dependency_skipped,
)
from ecoscope_workflows_core.tasks.skip import any_is_empty_df as any_is_empty_df
from ecoscope_workflows_core.tasks.transformation import map_columns as map_columns
from ecoscope_workflows_ext_ate.tasks import (
    calculate_elephant_sentiment_score as calculate_elephant_sentiment_score,
)
from ecoscope_workflows_ext_ate.tasks import (
    convert_object_to_string as convert_object_to_string,
)
from ecoscope_workflows_ext_ate.tasks import (
    convert_object_to_value as convert_object_to_value,
)
from ecoscope_workflows_ext_ate.tasks import create_likert_chart as create_likert_chart
from ecoscope_workflows_ext_ate.tasks import (
    draw_bar_and_persist as draw_bar_and_persist,
)
from ecoscope_workflows_ext_ate.tasks import (
    draw_boxplot_and_persist as draw_boxplot_and_persist,
)
from ecoscope_workflows_ext_ate.tasks import (
    draw_ols_scatterplot_and_persist as draw_ols_scatterplot_and_persist,
)
from ecoscope_workflows_ext_ate.tasks import (
    draw_pie_and_persist as draw_pie_and_persist,
)
from ecoscope_workflows_ext_ate.tasks import (
    draw_tukey_plots_and_persist as draw_tukey_plots_and_persist,
)
from ecoscope_workflows_ext_ate.tasks import exclude_value as exclude_value
from ecoscope_workflows_ext_ate.tasks import fill_missing_values as fill_missing_values
from ecoscope_workflows_ext_ate.tasks import (
    format_demographic_table as format_demographic_table,
)
from ecoscope_workflows_ext_ate.tasks import map_survey_columns as map_survey_columns
from ecoscope_workflows_ext_ate.tasks import (
    map_survey_responses as map_survey_responses,
)
from ecoscope_workflows_ext_ate.tasks import (
    perform_anova_analysis as perform_anova_analysis,
)
from ecoscope_workflows_ext_ate.tasks import persist_survey_word as persist_survey_word
from ecoscope_workflows_ext_custom.tasks.io import html_to_png as html_to_png
from ecoscope_workflows_ext_custom.tasks.io import load_df as load_df
from ecoscope_workflows_ext_custom.tasks.results import (
    create_scatterplot_layer as create_scatterplot_layer,
)
from ecoscope_workflows_ext_custom.tasks.results import draw_map as draw_map
from ecoscope_workflows_ext_custom.tasks.results import (
    set_base_maps_pydeck as set_base_maps_pydeck,
)
from ecoscope_workflows_ext_custom.tasks.spatial_ops import (
    reproject_gdf as reproject_gdf,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import get_events as get_events
from ecoscope_workflows_ext_ecoscope.tasks.io import persist_df as persist_df
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_color_map as apply_color_map,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    normalize_json_column as normalize_json_column,
)
from ecoscope_workflows_ext_mnc.tasks import bin_columns as bin_columns
from ecoscope_workflows_ext_mnc.tasks import categorize_bins as categorize_bins
from ecoscope_workflows_ext_mnc.tasks import convert_to_int as convert_to_int
from ecoscope_workflows_ext_mnc.tasks import (
    exclude_geom_outliers as exclude_geom_outliers,
)
from ecoscope_workflows_ext_mnc.tasks import filter_columns as filter_columns
from ecoscope_workflows_ext_mnc.tasks import merge_dataframes as merge_dataframes
from ecoscope_workflows_ext_ste.tasks import (
    combine_deckgl_map_layers as combine_deckgl_map_layers,
)
from ecoscope_workflows_ext_ste.tasks import (
    create_deckgl_layer_from_gdf as create_deckgl_layer_from_gdf,
)
from ecoscope_workflows_ext_ste.tasks import (
    fetch_and_persist_file as fetch_and_persist_file,
)
from ecoscope_workflows_ext_ste.tasks import get_gdf_geom_type as get_gdf_geom_type
from ecoscope_workflows_ext_ste.tasks import view_state_deck_gdf as view_state_deck_gdf

from ..params import Params


def main(params: Params):
    params_dict = json.loads(params.model_dump_json(exclude_unset=True))

    workflow_details = (
        set_workflow_details.validate()
        .set_task_instance_id("workflow_details")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(**(params_dict.get("workflow_details") or {}))
        .call()
    )

    time_range = (
        set_time_range.validate()
        .set_task_instance_id("time_range")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(**(params_dict.get("time_range") or {}))
        .call()
    )

    groupers = (
        set_groupers.validate()
        .set_task_instance_id("groupers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(groupers=[], **(params_dict.get("groupers") or {}))
        .call()
    )

    er_client_name = (
        set_er_connection.validate()
        .set_task_instance_id("er_client_name")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(**(params_dict.get("er_client_name") or {}))
        .call()
    )

    configure_base_maps = (
        set_base_maps_pydeck.validate()
        .set_task_instance_id("configure_base_maps")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            base_maps=[
                {
                    "url": "https://server.arcgisonline.com/arcgis/rest/services/Elevation/World_Hillshade/MapServer/tile/{z}/{y}/{x}",
                    "opacity": 1,
                    "max_zoom": 20,
                },
                {
                    "url": "https://server.arcgisonline.com/ArcGIS/rest/services/World_Street_Map/MapServer/tile/{z}/{y}/{x}",
                    "opacity": 0.25,
                    "max_zoom": 20,
                },
            ],
            **(params_dict.get("configure_base_maps") or {}),
        )
        .call()
    )

    download_ate_tpt = (
        fetch_and_persist_file.validate()
        .set_task_instance_id("download_ate_tpt")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            url="https://www.dropbox.com/scl/fi/w6tef8p7stj91shadgdey/ate_survey_template_280857.docx?rlkey=8ao2nk1z5hd4cbuskye84wx3p&st=v3divfq0&dl=0",
            output_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            overwrite_existing=False,
            retries=3,
            unzip=False,
            **(params_dict.get("download_ate_tpt") or {}),
        )
        .call()
    )

    download_ranch_bnds = (
        fetch_and_persist_file.validate()
        .set_task_instance_id("download_ranch_bnds")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            url="https://www.dropbox.com/scl/fi/b4yckfk2t077bhigb1k07/Amboseli-Ranch-Boundaries.gpkg?rlkey=kxiehp8f73j3y5g792jstwo0z&st=6hb6qwj9&dl=0",
            output_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            overwrite_existing=False,
            retries=3,
            unzip=False,
            **(params_dict.get("download_ranch_bnds") or {}),
        )
        .call()
    )

    download_ambo_sws = (
        fetch_and_persist_file.validate()
        .set_task_instance_id("download_ambo_sws")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            url="https://www.dropbox.com/scl/fi/1x5imkkvesnxv35kp8ngw/Amboseli-Swamps.gpkg?rlkey=n5rtu313zh0cg7o0cmbbt1jf4&st=zebggl8l&dl=0",
            output_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            overwrite_existing=False,
            retries=3,
            unzip=False,
            **(params_dict.get("download_ambo_sws") or {}),
        )
        .call()
    )

    download_national_parks = (
        fetch_and_persist_file.validate()
        .set_task_instance_id("download_national_parks")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            url="https://www.dropbox.com/scl/fi/7txo6s0tof8j0jp7j7lgk/National-Parks.gpkg?rlkey=yemiaztgu5scvlcdwapbkek9j&st=m9lz6abw&dl=0",
            output_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            overwrite_existing=False,
            retries=3,
            unzip=False,
            **(params_dict.get("download_national_parks") or {}),
        )
        .call()
    )

    load_ranch_boundaries = (
        load_df.validate()
        .set_task_instance_id("load_ranch_boundaries")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            file_path=download_ranch_bnds,
            layer=None,
            deserialize_json=False,
            **(params_dict.get("load_ranch_boundaries") or {}),
        )
        .call()
    )

    load_ambo_swamps = (
        load_df.validate()
        .set_task_instance_id("load_ambo_swamps")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            file_path=download_ambo_sws,
            layer=None,
            deserialize_json=False,
            **(params_dict.get("load_ambo_swamps") or {}),
        )
        .call()
    )

    load_national_parks = (
        load_df.validate()
        .set_task_instance_id("load_national_parks")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            file_path=download_national_parks,
            layer=None,
            deserialize_json=False,
            **(params_dict.get("load_national_parks") or {}),
        )
        .call()
    )

    reproject_ranch_boundaries = (
        reproject_gdf.validate()
        .set_task_instance_id("reproject_ranch_boundaries")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            gdf=load_ranch_boundaries,
            target_crs="epsg:4326",
            **(params_dict.get("reproject_ranch_boundaries") or {}),
        )
        .call()
    )

    reproject_ambo_swamps = (
        reproject_gdf.validate()
        .set_task_instance_id("reproject_ambo_swamps")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            gdf=load_ambo_swamps,
            target_crs="epsg:4326",
            **(params_dict.get("reproject_ambo_swamps") or {}),
        )
        .call()
    )

    reproject_national_parks = (
        reproject_gdf.validate()
        .set_task_instance_id("reproject_national_parks")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            gdf=load_national_parks,
            target_crs="epsg:4326",
            **(params_dict.get("reproject_national_parks") or {}),
        )
        .call()
    )

    assign_ranch_boundaries = (
        get_gdf_geom_type.validate()
        .set_task_instance_id("assign_ranch_boundaries")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            gdf=reproject_ranch_boundaries,
            **(params_dict.get("assign_ranch_boundaries") or {}),
        )
        .call()
    )

    assign_ambo_swamps = (
        get_gdf_geom_type.validate()
        .set_task_instance_id("assign_ambo_swamps")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            gdf=reproject_ambo_swamps, **(params_dict.get("assign_ambo_swamps") or {})
        )
        .call()
    )

    assign_national_parks = (
        get_gdf_geom_type.validate()
        .set_task_instance_id("assign_national_parks")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            gdf=reproject_national_parks,
            **(params_dict.get("assign_national_parks") or {}),
        )
        .call()
    )

    create_ranch_bnds_layers = (
        create_deckgl_layer_from_gdf.validate()
        .set_task_instance_id("create_ranch_bnds_layers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            gdf=assign_ranch_boundaries,
            style={
                "extruded": False,
                "get_fill_color": [0, 0, 0],
                "get_line_color": [0, 0, 0],
                "get_line_width": 2.25,
                "stroked": True,
                "filled": False,
                "opacity": 0.45,
            },
            legend={
                "title": "Map layers",
                "values": [{"label": "Ranch boundaries", "color": "#000000"}],
            },
            **(params_dict.get("create_ranch_bnds_layers") or {}),
        )
        .call()
    )

    create_ambo_swamp_layers = (
        create_deckgl_layer_from_gdf.validate()
        .set_task_instance_id("create_ambo_swamp_layers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            gdf=assign_ambo_swamps,
            style={
                "extruded": False,
                "get_fill_color": [96, 156, 181],
                "get_line_color": [96, 156, 181],
                "get_line_width": 0.5,
                "stroked": True,
                "filled": True,
                "opacity": 0.45,
            },
            legend={"title": "", "values": [{"label": "Swamps", "color": "#609cb5"}]},
            **(params_dict.get("create_ambo_swamp_layers") or {}),
        )
        .call()
    )

    create_national_layers = (
        create_deckgl_layer_from_gdf.validate()
        .set_task_instance_id("create_national_layers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            gdf=assign_national_parks,
            style={
                "extruded": False,
                "get_fill_color": [76, 140, 43],
                "get_line_color": [76, 140, 43],
                "get_line_width": 0.75,
                "stroked": True,
                "filled": True,
                "opacity": 0.45,
            },
            legend={
                "title": "",
                "values": [{"label": "National parks", "color": "#4c8c2b"}],
            },
            **(params_dict.get("create_national_layers") or {}),
        )
        .call()
    )

    get_survey_events = (
        get_events.validate()
        .set_task_instance_id("get_survey_events")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            client=er_client_name,
            time_range=time_range,
            event_columns=[
                "id",
                "time",
                "event_type",
                "event_category",
                "reported_by",
                "serial_number",
                "geometry",
                "created_at",
                "event_details",
                "patrols",
            ],
            event_types=["atequestionnaire_rep"],
            raise_on_empty=True,
            include_details=True,
            include_updates=False,
            include_related_events=False,
            include_null_geometry=False,
            include_display_values=False,
            **(params_dict.get("get_survey_events") or {}),
        )
        .call()
    )

    filter_events = (
        exclude_value.validate()
        .set_task_instance_id("filter_events")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=get_survey_events,
            column="event_details",
            value=46283,
            **(params_dict.get("filter_events") or {}),
        )
        .call()
    )

    normalize_event_details = (
        normalize_json_column.validate()
        .set_task_instance_id("normalize_event_details")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            column="event_details",
            df=filter_events,
            skip_if_not_exists=True,
            sort_columns=True,
            **(params_dict.get("normalize_event_details") or {}),
        )
        .call()
    )

    rename_survey_columns = (
        map_columns.validate()
        .set_task_instance_id("rename_survey_columns")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            raise_if_not_found=True,
            df=normalize_event_details,
            drop_columns=[
                "event_category",
                "reported_by",
                "event_details__updates",
                "event_details__end_time",
                "event_details__closing_statement",
                "event_details__participant_occupationifother",
                "event_details__livestock_health_1_otheranimals",
                "event_details__livestock_health_3_otheranimals",
                "event_details__participant_tribeifother",
                "event_details__participant_land_tenureifother",
                "event_details__behaviour_2",
                "event_details__behaviour_4_ifyes",
                "event_details__one_health_7",
                "event_details__livestock_health_4",
                "event_details__livestock_health_5",
                "event_details__livestock_health_6",
                "event_details__behaviour_killing_2",
                "event_details__behaviour_killing_3",
                "event_details__perception_challenges",
                "event_details__participant_occupation",
                "event_details__water_mitigation_use_2",
                "event_details__livestock_health_3_cattle",
                "event_details__livestock_health_3_donkies",
                "event_details__livestock_health_3_sheepgoat",
                "event_details__perception_conservation_interventions_6",
                "event_details__perception_conservation_interventions_4ifyes",
                "event_details__perception_conservation_interventions_2_ifnowhy",
                "event_details__belief_costs_4",
                "event_details__belief_benefits_4",
                "event_details__crop_mitigation_2",
                "event_details__perception_crop_production_threatsifother",
                "event_details__perception_conservation_interventions_5ifother",
                "event_details__one_health_8_ifyes",
                "event_details__participant_tribeifother",
                "event_details__participant_land_tenureifother",
                "event_details__livestock_health_3_dogs",
            ],
            retain_columns=[],
            rename_columns={
                "event_details__participant_age": "Participant age",
                "event_details__participant_tribe": "Participant tribe",
                "event_details__participant_gender": "Participant gender",
                "event_details__elephant_knowledge_1": "Female elephants live in family groups",
                "event_details__elephant_knowledge_2": "Female elephants protect their young",
                "event_details__participant_num_cows": "Number of cows",
                "event_details__participant_age_range": "Participant age group",
                "event_details__participant_agreement": "Respondent agreed to interview",
                "event_details__participant_household": "Household size",
                "event_details__participant_land_owned": "Land owned (acres)",
                "event_details__participant_num_shoats": "Number of shoats",
                "event_details__participant_agricultural_land": "Agricultural land (acres)",
                "event_details__participant_duration_in_amboseli": "Years living in area",
                "event_details__belief_1": "Humans and elephants can live together",
                "event_details__attitude_0": "Overall feelings about wildlife",
                "event_details__attitude_1": "Opinion on having elephants in the area",
                "event_details__attitude_2": "Importance of elephants living here",
                "event_details__attitude_3": "Elephants should only live inside parks",
                "event_details__exposure_1": "How often seen elephants in the last year",
                "event_details__exposure_2": "See more elephants now than before",
                "event_details__behaviour_1": "Do you change routes or schedules because of elephants",
                "event_details__behaviour_3": "Effectiveness rating of that practice",
                "event_details__behaviour_4": "What do you do when you encounter elephants on foot",
                "event_details__one_health_8": "Noticed signs of illness in wild animals",
                "event_details__belief_costs_1": "Elephants harm community members",
                "event_details__belief_costs_2": "Elephants negatively affect my livelihood",
                "event_details__belief_costs_3": "Elephants impact my emotional wellbeing",
                "event_details__future_activity": "Willingness to join future community dialogue",
                "event_details__attitude_killing": "Reaction to hearing about elephants being harmed",
                "event_details__belief_benefits_1": "Receive livelihood benefits from elephants",
                "event_details__belief_benefits_2": "Benefit from enjoying seeing elephants",
                "event_details__belief_benefits_3": "Elephants are important for a healthy ecosystem",
                "event_details__crop_mitigation_1": "Use measures to protect crops from elephants",
                "event_details__behaviour_killing_1": "Ever been involved in or witnessed an elephant harmed",
                "event_details__hazard_acceptance_1": "Acceptable to harm elephants if they damage property or livestock",
                "event_details__hazard_acceptance_2": "Acceptable to harm elephants if people are hurt",
                "event_details__elephant_knowledge_3": "Elephants can smell and hear from far away",
                "event_details__elephant_knowledge_4": "Elephants move seasonally for food and water",
                "event_details__elephant_knowledge_6": "Elephant may shake its head when annoyed",
                "event_details__elephant_knowledge_7": "Elephant signals awareness by raising trunk",
                "event_details__elephant_knowledge_8": "Male elephants with secretions may be more aggressive",
                "event_details__participant_education": "Highest level of education",
                "event_details__livestock_mitigation_1": "Use measures to protect livestock from elephants",
                "event_details__water_mitigation_use_1": "Protect water sources from elephants",
                "event_details__water_mitigation_use_3": "Effectiveness rating of water protection",
                "event_details__livestock_health_1_dogs": "Number of dogs",
                "event_details__participant_land_tenure": "Land tenure",
                "event_details__livestock_health_1_cattle": "Number of cattle",
                "event_details__livestock_health_1_donkies": "Number of donkeys",
                "event_details__participant_marital_status": "Marital status",
                "event_details__livestock_health_1_sheepgoat": "Number of sheep or goats",
                "event_details__perception_livestock_threats": "Greatest threat to your livestock",
                "event_details__perception_crop_production_threats": "Greatest threat to crop production",
                "event_details__perception_conservation_interventions_1": "Benefit from the KCCDT Big Life electric fence",
                "event_details__perception_conservation_interventions_2": "Pay into fence maintenance fund",
                "event_details__perception_conservation_interventions_4": "Do you report elephant conflict incidents",
                "event_details__perception_conservation_interventions_5": "Which intervention would help you in future",
                "event_details__crop_mitigation_3": "Effectiveness rating of primary crop protection method",
                "event_details__livestock_mitigation_2": "If yes, which methods do you use for livestock",
            },
            **(params_dict.get("rename_survey_columns") or {}),
        )
        .call()
    )

    convert_obj_to_num = (
        convert_object_to_value.validate()
        .set_task_instance_id("convert_obj_to_num")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=rename_survey_columns,
            columns=[
                "Participant age",
                "Number of cows",
                "Household size",
                "Land owned (acres)",
                "Number of shoats",
                "Agricultural land (acres)",
                "Number of sheep or goats",
                "Number of dogs",
                "Number of cattle",
                "Number of donkeys",
            ],
            **(params_dict.get("convert_obj_to_num") or {}),
        )
        .call()
    )

    convert_obj_to_str = (
        convert_object_to_string.validate()
        .set_task_instance_id("convert_obj_to_str")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=convert_obj_to_num,
            columns=[
                "id",
                "Participant tribe",
                "Participant gender",
                "Female elephants live in family groups",
                "Female elephants protect their young",
                "Participant age group",
                "Respondent agreed to interview",
                "Years living in area",
                "Humans and elephants can live together",
                "Overall feelings about wildlife",
                "Opinion on having elephants in the area",
                "Importance of elephants living here",
                "Elephants should only live inside parks",
                "How often seen elephants in the last year",
                "See more elephants now than before",
                "Do you change routes or schedules because of elephants",
                "Effectiveness rating of that practice",
                "What do you do when you encounter elephants on foot",
                "Noticed signs of illness in wild animals",
                "Elephants harm community members",
                "Elephants negatively affect my livelihood",
                "Elephants impact my emotional wellbeing",
                "Willingness to join future community dialogue",
                "Reaction to hearing about elephants being harmed",
                "Receive livelihood benefits from elephants",
                "Benefit from enjoying seeing elephants",
                "Elephants are important for a healthy ecosystem",
                "Use measures to protect crops from elephants",
                "Ever been involved in or witnessed an elephant harmed",
                "Acceptable to harm elephants if they damage property or livestock",
                "Acceptable to harm elephants if people are hurt",
                "Elephants can smell and hear from far away",
                "Elephants move seasonally for food and water",
                "Elephant may shake its head when annoyed",
                "Elephant signals awareness by raising trunk",
                "Male elephants with secretions may be more aggressive",
                "Highest level of education",
                "Use measures to protect livestock from elephants",
                "Protect water sources from elephants",
                "Effectiveness rating of water protection",
                "Land tenure",
                "Marital status",
                "Greatest threat to your livestock",
                "Greatest threat to crop production",
                "Benefit from the KCCDT Big Life electric fence",
                "Pay into fence maintenance fund",
                "Do you report elephant conflict incidents",
                "Which intervention would help you in future",
                "Effectiveness rating of primary crop protection method",
                "If yes, which methods do you use for livestock",
            ],
            **(params_dict.get("convert_obj_to_str") or {}),
        )
        .call()
    )

    fill_values = (
        fill_missing_values.validate()
        .set_task_instance_id("fill_values")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            dataframe=convert_obj_to_str,
            numeric_fill_value=0,
            categorical_fill_value="Unspecified",
            numeric_columns=[
                "Participant age",
                "Number of cows",
                "Household size",
                "Land owned (acres)",
                "Number of shoats",
                "Agricultural land (acres)",
                "Number of sheep or goats",
                "Number of dogs",
                "Number of cattle",
                "Number of donkeys",
            ],
            categorical_columns=[
                "id",
                "Participant tribe",
                "Participant gender",
                "Female elephants live in family groups",
                "Female elephants protect their young",
                "Participant age group",
                "Respondent agreed to interview",
                "Years living in area",
                "Humans and elephants can live together",
                "Overall feelings about wildlife",
                "Opinion on having elephants in the area",
                "Importance of elephants living here",
                "Elephants should only live inside parks",
                "How often seen elephants in the last year",
                "See more elephants now than before",
                "Do you change routes or schedules because of elephants",
                "Effectiveness rating of that practice",
                "What do you do when you encounter elephants on foot",
                "Noticed signs of illness in wild animals",
                "Elephants harm community members",
                "Elephants negatively affect my livelihood",
                "Elephants impact my emotional wellbeing",
                "Willingness to join future community dialogue",
                "Reaction to hearing about elephants being harmed",
                "Receive livelihood benefits from elephants",
                "Benefit from enjoying seeing elephants",
                "Elephants are important for a healthy ecosystem",
                "Use measures to protect crops from elephants",
                "Ever been involved in or witnessed an elephant harmed",
                "Acceptable to harm elephants if they damage property or livestock",
                "Acceptable to harm elephants if people are hurt",
                "Elephants can smell and hear from far away",
                "Elephants move seasonally for food and water",
                "Elephant may shake its head when annoyed",
                "Elephant signals awareness by raising trunk",
                "Male elephants with secretions may be more aggressive",
                "Highest level of education",
                "Use measures to protect livestock from elephants",
                "Protect water sources from elephants",
                "Effectiveness rating of water protection",
                "Land tenure",
                "Marital status",
                "Greatest threat to your livestock",
                "Greatest threat to crop production",
                "Benefit from the KCCDT Big Life electric fence",
                "Pay into fence maintenance fund",
                "Do you report elephant conflict incidents",
                "Which intervention would help you in future",
                "Effectiveness rating of primary crop protection method",
                "If yes, which methods do you use for livestock",
            ],
            **(params_dict.get("fill_values") or {}),
        )
        .call()
    )

    map_agree_disagree = (
        map_survey_responses.validate()
        .set_task_instance_id("map_agree_disagree")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            inplace=False,
            df=fill_values,
            columns=[
                "Humans and elephants can live together",
                "Importance of elephants living here",
                "Elephants should only live inside parks",
                "Elephants harm community members",
                "Elephants negatively affect my livelihood",
                "Elephants impact my emotional wellbeing",
                "Benefit from enjoying seeing elephants",
                "Elephants are important for a healthy ecosystem",
                "Acceptable to harm elephants if they damage property or livestock",
                "Acceptable to harm elephants if people are hurt",
                "Receive livelihood benefits from elephants",
            ],
            value_map={
                "strongly_agree": "Strongly agree",
                "agree": "Agree",
                "neutral": "Neutral",
                "disagree": "Disagree",
                "strongly_disagree": "Strongly disagree",
                "i_dont_know": "I dont know",
                "prefer_not_to_answer": "Prefer not to answer",
            },
            **(params_dict.get("map_agree_disagree") or {}),
        )
        .call()
    )

    map_true_false = (
        map_survey_responses.validate()
        .set_task_instance_id("map_true_false")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            inplace=False,
            df=map_agree_disagree,
            columns=[
                "Female elephants live in family groups",
                "Female elephants protect their young",
                "Elephants move seasonally for food and water",
                "Elephant may shake its head when annoyed",
                "Elephant signals awareness by raising trunk",
                "Male elephants with secretions may be more aggressive",
                "Elephants can smell and hear from far away",
            ],
            value_map={"false": "False", "true": "True", "i_dont_know": "I dont know"},
            **(params_dict.get("map_true_false") or {}),
        )
        .call()
    )

    map_no_effect = (
        map_survey_responses.validate()
        .set_task_instance_id("map_no_effect")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            inplace=False,
            df=map_true_false,
            columns=[
                "Effectiveness rating of primary crop protection method",
                "Effectiveness rating of that practice",
                "Effectiveness rating of water protection",
            ],
            value_map={
                "highly_effective": "Highly effective",
                "effective": "Effective",
                "not_effective": "Not effective",
                "i_dont_know": "I dont know",
            },
            **(params_dict.get("map_no_effect") or {}),
        )
        .call()
    )

    map_col_surveys = (
        map_survey_columns.validate()
        .set_task_instance_id("map_col_surveys")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=map_no_effect,
            cols=[
                "Participant age",
                "Household size",
                "Participant tribe",
                "Participant gender",
                "Participant age group",
                "Years living in area",
                "Overall feelings about wildlife",
                "Opinion on having elephants in the area",
                "How often seen elephants in the last year",
                "What do you do when you encounter elephants on foot",
                "Reaction to hearing about elephants being harmed",
                "Highest level of education",
                "Greatest threat to your livestock",
                "Greatest threat to crop production",
                "Which intervention would help you in future",
                "Marital status",
                "Land tenure",
                "Humans and elephants can live together",
                "Importance of elephants living here",
                "Elephants should only live inside parks",
                "Elephants harm community members",
                "Elephants negatively affect my livelihood",
                "Elephants impact my emotional wellbeing",
                "Benefit from enjoying seeing elephants",
                "Elephants are important for a healthy ecosystem",
                "Acceptable to harm elephants if they damage property or livestock",
                "Acceptable to harm elephants if people are hurt",
                "Receive livelihood benefits from elephants",
            ],
            **(params_dict.get("map_col_surveys") or {}),
        )
        .call()
    )

    convt_to_int = (
        convert_to_int.validate()
        .set_task_instance_id("convt_to_int")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            errors="coerce",
            fill_value=0,
            inplace=False,
            df=map_col_surveys,
            columns=[
                "Participant age",
                "Number of cows",
                "Household size",
                "Number of shoats",
                "Agricultural land (acres)",
                "Number of sheep or goats",
                "Number of dogs",
                "Number of cattle",
                "Number of donkeys",
            ],
            **(params_dict.get("convt_to_int") or {}),
        )
        .call()
    )

    create_demo_table = (
        format_demographic_table.validate()
        .set_task_instance_id("create_demo_table")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=convt_to_int,
            columns_of_interest=[
                "Participant gender",
                "Participant age",
                "Participant tribe",
                "Household size",
                "Highest level of education",
            ],
            **(params_dict.get("create_demo_table") or {}),
        )
        .call()
    )

    persist_demo_df = (
        persist_df.validate()
        .set_task_instance_id("persist_demo_df")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            df=create_demo_table,
            filetype="csv",
            filename="demographic_table",
            **(params_dict.get("persist_demo_df") or {}),
        )
        .call()
    )

    bin_survey_cols = (
        bin_columns.validate()
        .set_task_instance_id("bin_survey_cols")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=convt_to_int,
            bins=5,
            suffix="bins",
            inplace=True,
            columns=[
                "Participant age",
                "Number of cows",
                "Household size",
                "Number of shoats",
                "Land owned (acres)",
                "Agricultural land (acres)",
                "Number of dogs",
                "Number of cattle",
                "Number of donkeys",
                "Number of sheep or goats",
            ],
            **(params_dict.get("bin_survey_cols") or {}),
        )
        .call()
    )

    categorize_household = (
        categorize_bins.validate()
        .set_task_instance_id("categorize_household")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=bin_survey_cols,
            col="Household sizebins",
            **(params_dict.get("categorize_household") or {}),
        )
        .call()
    )

    categorize_age = (
        categorize_bins.validate()
        .set_task_instance_id("categorize_age")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=bin_survey_cols,
            col="Participant agebins",
            **(params_dict.get("categorize_age") or {}),
        )
        .call()
    )

    filter_elephant_qs = (
        filter_columns.validate()
        .set_task_instance_id("filter_elephant_qs")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=categorize_age,
            exclude=None,
            columns=[
                "Humans and elephants can live together",
                "Importance of elephants living here",
                "Elephants should only live inside parks",
                "Elephants harm community members",
                "Elephants negatively affect my livelihood",
                "Elephants impact my emotional wellbeing",
                "Benefit from enjoying seeing elephants",
                "Elephants are important for a healthy ecosystem",
                "Acceptable to harm elephants if they damage property or livestock",
                "Acceptable to harm elephants if people are hurt",
                "Receive livelihood benefits from elephants",
            ],
            **(params_dict.get("filter_elephant_qs") or {}),
        )
        .call()
    )

    draw_likert_chart = (
        create_likert_chart.validate()
        .set_task_instance_id("draw_likert_chart")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=filter_elephant_qs,
            title="Agree/Disagree",
            height_per_question=60,
            min_height=400,
            width=1200,
            show_percentages=True,
            sort_questions=False,
            sort_by="positive",
            response_order=[
                "Strongly disagree",
                "Disagree",
                "Neutral",
                "Agree",
                "Strongly agree",
            ],
            neutral_categories=["Neutral"],
            colors={
                "Strongly disagree": "#2c5282",
                "Disagree": "#4299e1",
                "Neutral": "#a0aec0",
                "Unspecified": "#a0aec0",
                "I dont know": "#a0aec0",
                "Agree": "#ed8936",
                "Strongly agree": "#c05621",
            },
            **(params_dict.get("draw_likert_chart") or {}),
        )
        .call()
    )

    persist_likert = (
        persist_text.validate()
        .set_task_instance_id("persist_likert")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            text=draw_likert_chart,
            filename="elephants_relationship_likert.html",
            **(params_dict.get("persist_likert") or {}),
        )
        .call()
    )

    filter_eff_noeff = (
        filter_columns.validate()
        .set_task_instance_id("filter_eff_noeff")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=bin_survey_cols,
            exclude=None,
            columns=[
                "Effectiveness rating of primary crop protection method",
                "Effectiveness rating of that practice",
                "Effectiveness rating of water protection",
            ],
            **(params_dict.get("filter_eff_noeff") or {}),
        )
        .call()
    )

    draw_likert_eff = (
        create_likert_chart.validate()
        .set_task_instance_id("draw_likert_eff")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=filter_eff_noeff,
            title="Effective/Not effective",
            height_per_question=60,
            min_height=400,
            width=1200,
            show_percentages=True,
            sort_questions=False,
            sort_by="positive",
            response_order=["Not effective", "Effective", "Highly effective"],
            neutral_categories=["I dont know"],
            colors={
                "Not effective": "#D64545",
                "I dont know": "#A8A8A8",
                "Unspecified": "#D4D4D4",
                "Effective": "#2A9D8F",
                "Highly effective": "#2E7D32",
            },
            **(params_dict.get("draw_likert_eff") or {}),
        )
        .call()
    )

    persist_likert_eff = (
        persist_text.validate()
        .set_task_instance_id("persist_likert_eff")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            text=draw_likert_eff,
            filename="effectiveness_mitigation_methods.html",
            **(params_dict.get("persist_likert_eff") or {}),
        )
        .call()
    )

    draw_survey_pies = (
        draw_pie_and_persist.validate()
        .set_task_instance_id("draw_survey_pies")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            df=bin_survey_cols,
            columns=[
                "Participant gender",
                "Female elephants live in family groups",
                "Female elephants protect their young",
                "Participant age group",
                "See more elephants now than before",
                "Do you change routes or schedules because of elephants",
                "What do you do when you encounter elephants on foot",
                "Noticed signs of illness in wild animals",
                "Willingness to join future community dialogue",
                "Use measures to protect crops from elephants",
                "Ever been involved in or witnessed an elephant harmed",
                "Elephants can smell and hear from far away",
                "Elephants move seasonally for food and water",
                "Elephant may shake its head when annoyed",
                "Elephant signals awareness by raising trunk",
                "Male elephants with secretions may be more aggressive",
                "Highest level of education",
                "Use measures to protect livestock from elephants",
                "Protect water sources from elephants",
                "Marital status",
                "Greatest threat to your livestock",
                "Benefit from the KCCDT Big Life electric fence",
                "Pay into fence maintenance fund",
                "Do you report elephant conflict incidents",
                "Which intervention would help you in future",
                "Opinion on having elephants in the area",
            ],
            **(params_dict.get("draw_survey_pies") or {}),
        )
        .call()
    )

    draw_survey_bar = (
        draw_bar_and_persist.validate()
        .set_task_instance_id("draw_survey_bar")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            df=bin_survey_cols,
            columns=[
                "Participant tribe",
                "Years living in area",
                "Overall feelings about wildlife",
                "How often seen elephants in the last year",
                "Reaction to hearing about elephants being harmed",
                "Land tenure",
                "Greatest threat to crop production",
                "Household sizebins",
                "Participant agebins",
            ],
            **(params_dict.get("draw_survey_bar") or {}),
        )
        .call()
    )

    filter_attitude_cols = (
        filter_columns.validate()
        .set_task_instance_id("filter_attitude_cols")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=convt_to_int,
            exclude=None,
            columns=[
                "id",
                "geometry",
                "Humans and elephants can live together",
                "Importance of elephants living here",
                "Elephants should only live inside parks",
                "Elephants harm community members",
                "Elephants negatively affect my livelihood",
                "Elephants impact my emotional wellbeing",
                "Benefit from enjoying seeing elephants",
                "Elephants are important for a healthy ecosystem",
                "Acceptable to harm elephants if they damage property or livestock",
                "Acceptable to harm elephants if people are hurt",
                "Receive livelihood benefits from elephants",
            ],
            **(params_dict.get("filter_attitude_cols") or {}),
        )
        .call()
    )

    calc_attitude_scores = (
        calculate_elephant_sentiment_score.validate()
        .set_task_instance_id("calc_attitude_scores")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=filter_attitude_cols,
            positive_columns=[
                "Humans and elephants can live together",
                "Importance of elephants living here",
                "Benefit from enjoying seeing elephants",
                "Elephants are important for a healthy ecosystem",
                "Receive livelihood benefits from elephants",
            ],
            negative_columns=[
                "Elephants should only live inside parks",
                "Elephants harm community members",
                "Elephants negatively affect my livelihood",
                "Elephants impact my emotional wellbeing",
                "Acceptable to harm elephants if they damage property or livestock",
                "Acceptable to harm elephants if people are hurt",
            ],
            **(params_dict.get("calc_attitude_scores") or {}),
        )
        .call()
    )

    persist_attitude_df = (
        persist_df.validate()
        .set_task_instance_id("persist_attitude_df")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            df=calc_attitude_scores,
            filename="elephant_sentiment_scores",
            filetype="csv",
            **(params_dict.get("persist_attitude_df") or {}),
        )
        .call()
    )

    filter_stat_qs = (
        filter_columns.validate()
        .set_task_instance_id("filter_stat_qs")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=bin_survey_cols,
            exclude=None,
            columns=[
                "id",
                "Participant age",
                "Marital status",
                "Highest level of education",
                "Participant tribe",
                "Household size",
                "Participant age group",
                "Participant gender",
            ],
            **(params_dict.get("filter_stat_qs") or {}),
        )
        .call()
    )

    merge_stat_ele = (
        merge_dataframes.validate()
        .set_task_instance_id("merge_stat_ele")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            left_df=filter_stat_qs,
            right_df=calc_attitude_scores,
            on="id",
            how="left",
            preserve_left_index=False,
            **(params_dict.get("merge_stat_ele") or {}),
        )
        .call()
    )

    map_stats_df = (
        map_columns.validate()
        .set_task_instance_id("map_stats_df")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            raise_if_not_found=True,
            df=merge_stat_ele,
            drop_columns=[],
            retain_columns=[],
            rename_columns={
                "id": "id",
                "Participant age": "age",
                "Marital status": "marital_status",
                "Highest level of education": "education_level",
                "Participant tribe": "tribe",
                "Household size": "household_size",
                "Participant age group": "age_group_distribution",
                "Participant gender": "gender_of_participant",
            },
            **(params_dict.get("map_stats_df") or {}),
        )
        .call()
    )

    perform_anova = (
        perform_anova_analysis.validate()
        .set_task_instance_id("perform_anova")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            dataframe=map_stats_df,
            target_column="elephant_sentiment_score",
            factor_columns=[
                "gender_of_participant",
                "age_group_distribution",
                "education_level",
                "marital_status",
            ],
            anova_type=2,
            **(params_dict.get("perform_anova") or {}),
        )
        .call()
    )

    persist_anova_df = (
        persist_df.validate()
        .set_task_instance_id("persist_anova_df")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            df=perform_anova,
            filename="anova_results",
            filetype="csv",
            **(params_dict.get("persist_anova_df") or {}),
        )
        .call()
    )

    draw_stat_box = (
        draw_boxplot_and_persist.validate()
        .set_task_instance_id("draw_stat_box")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            df=map_stats_df,
            columns=[
                "marital_status",
                "education_level",
                "tribe",
                "age_group_distribution",
                "gender_of_participant",
            ],
            y_column="elephant_sentiment_score",
            **(params_dict.get("draw_stat_box") or {}),
        )
        .call()
    )

    draw_ols_plots = (
        draw_ols_scatterplot_and_persist.validate()
        .set_task_instance_id("draw_ols_plots")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            df=map_stats_df,
            columns=["age", "household_size"],
            y_column="elephant_sentiment_score",
            **(params_dict.get("draw_ols_plots") or {}),
        )
        .call()
    )

    draw_tukey_plots = (
        draw_tukey_plots_and_persist.validate()
        .set_task_instance_id("draw_tukey_plots")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            df=map_stats_df,
            columns=[
                "education_level",
                "age_group_distribution",
                "gender_of_participant",
                "marital_status",
            ],
            value_column="elephant_sentiment_score",
            **(params_dict.get("draw_tukey_plots") or {}),
        )
        .call()
    )

    remove_geom_outliers = (
        exclude_geom_outliers.validate()
        .set_task_instance_id("remove_geom_outliers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=calc_attitude_scores,
            z_threshold=3,
            **(params_dict.get("remove_geom_outliers") or {}),
        )
        .call()
    )

    apply_att_colormap = (
        apply_color_map.validate()
        .set_task_instance_id("apply_att_colormap")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            input_column_name="overall_attitude",
            output_column_name="attitude_colors",
            colormap=["#FF0000", "#FFA500", "#FFFF00", "#00FF00", "#0000FF"],
            df=remove_geom_outliers,
            **(params_dict.get("apply_att_colormap") or {}),
        )
        .call()
    )

    generate_attitude_layers = (
        create_scatterplot_layer.validate()
        .set_task_instance_id("generate_attitude_layers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            layer_style={
                "get_fill_color": "attitude_colors",
                "get_line_color": [0, 0, 0],
                "get_radius": 4,
                "get_line_width": 0.25,
                "opacity": 0.75,
                "stroked": True,
            },
            legend={
                "title": "Attitude scores",
                "label_column": "overall_attitude",
                "color_column": "attitude_colors",
                "sort": "ascending",
            },
            geodataframe=apply_att_colormap,
            **(params_dict.get("generate_attitude_layers") or {}),
        )
        .call()
    )

    combine_attitude_scores = (
        combine_deckgl_map_layers.validate()
        .set_task_instance_id("combine_attitude_scores")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            static_layers=[
                create_ranch_bnds_layers,
                create_ambo_swamp_layers,
                create_national_layers,
            ],
            grouped_layers=generate_attitude_layers,
            **(params_dict.get("combine_attitude_scores") or {}),
        )
        .call()
    )

    global_zoom = (
        view_state_deck_gdf.validate()
        .set_task_instance_id("global_zoom")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            pitch=0,
            bearing=0,
            gdf=reproject_ranch_boundaries,
            **(params_dict.get("global_zoom") or {}),
        )
        .call()
    )

    draw_att_map = (
        draw_map.validate()
        .set_task_instance_id("draw_att_map")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            tile_layers=configure_base_maps,
            static=False,
            title=None,
            max_zoom=10,
            legend_style={"placement": "bottom-right"},
            geo_layers=combine_attitude_scores,
            view_state=global_zoom,
            **(params_dict.get("draw_att_map") or {}),
        )
        .call()
    )

    persist_att_ecomap_urls = (
        persist_text.validate()
        .set_task_instance_id("persist_att_ecomap_urls")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            text=draw_att_map,
            filename="attitude_scores_community.html",
            **(params_dict.get("persist_att_ecomap_urls") or {}),
        )
        .call()
    )

    remove_geom_gn_outliers = (
        exclude_geom_outliers.validate()
        .set_task_instance_id("remove_geom_gn_outliers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=bin_survey_cols,
            z_threshold=3,
            **(params_dict.get("remove_geom_gn_outliers") or {}),
        )
        .call()
    )

    apply_gn_colormap = (
        apply_color_map.validate()
        .set_task_instance_id("apply_gn_colormap")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            input_column_name="Participant gender",
            output_column_name="gender_colors",
            colormap=["#FFC0CB", "#0000FF", "#DC143C"],
            df=remove_geom_gn_outliers,
            **(params_dict.get("apply_gn_colormap") or {}),
        )
        .call()
    )

    generate_gender_layers = (
        create_scatterplot_layer.validate()
        .set_task_instance_id("generate_gender_layers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            layer_style={
                "get_fill_color": "gender_colors",
                "get_line_color": [0, 0, 0],
                "get_line_width": 0.25,
                "get_radius": 4,
                "opacity": 0.75,
                "stroked": True,
            },
            legend={
                "title": "Gender",
                "label_column": "Participant gender",
                "color_column": "gender_colors",
                "sort": "ascending",
            },
            geodataframe=apply_gn_colormap,
            **(params_dict.get("generate_gender_layers") or {}),
        )
        .call()
    )

    combine_gender_layers = (
        combine_deckgl_map_layers.validate()
        .set_task_instance_id("combine_gender_layers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            static_layers=[
                create_ranch_bnds_layers,
                create_ambo_swamp_layers,
                create_national_layers,
            ],
            grouped_layers=generate_gender_layers,
            **(params_dict.get("combine_gender_layers") or {}),
        )
        .call()
    )

    draw_gender_map = (
        draw_map.validate()
        .set_task_instance_id("draw_gender_map")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            tile_layers=configure_base_maps,
            static=False,
            title=None,
            max_zoom=10,
            legend_style={"placement": "bottom-right"},
            geo_layers=combine_gender_layers,
            view_state=global_zoom,
            **(params_dict.get("draw_gender_map") or {}),
        )
        .call()
    )

    persist_gn_ecomap_urls = (
        persist_text.validate()
        .set_task_instance_id("persist_gn_ecomap_urls")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            text=draw_gender_map,
            filename="gender_distribution_ecomap.html",
            **(params_dict.get("persist_gn_ecomap_urls") or {}),
        )
        .call()
    )

    remove_geom_ov_outliers = (
        exclude_geom_outliers.validate()
        .set_task_instance_id("remove_geom_ov_outliers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            df=bin_survey_cols,
            z_threshold=3,
            **(params_dict.get("remove_geom_ov_outliers") or {}),
        )
        .call()
    )

    generate_survey_layers = (
        create_scatterplot_layer.validate()
        .set_task_instance_id("generate_survey_layers")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            layer_style={
                "get_fill_color": [199, 0, 57],
                "get_line_color": [0, 0, 0],
                "get_line_width": 0.25,
                "get_radius": 4,
                "opacity": 0.75,
                "stroked": True,
            },
            legend={
                "title": "Legend",
                "values": [{"label": "Survey location", "color": "#C70039"}],
            },
            geodataframe=remove_geom_ov_outliers,
            **(params_dict.get("generate_survey_layers") or {}),
        )
        .call()
    )

    combine_survey_locations = (
        combine_deckgl_map_layers.validate()
        .set_task_instance_id("combine_survey_locations")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            static_layers=[
                create_ranch_bnds_layers,
                create_ambo_swamp_layers,
                create_national_layers,
            ],
            grouped_layers=generate_survey_layers,
            **(params_dict.get("combine_survey_locations") or {}),
        )
        .call()
    )

    draw_survey_map = (
        draw_map.validate()
        .set_task_instance_id("draw_survey_map")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            tile_layers=configure_base_maps,
            static=False,
            title=None,
            max_zoom=10,
            legend_style={"placement": "bottom-right"},
            geo_layers=combine_survey_locations,
            view_state=global_zoom,
            **(params_dict.get("draw_survey_map") or {}),
        )
        .call()
    )

    persist_ov_ecomap_urls = (
        persist_text.validate()
        .set_task_instance_id("persist_ov_ecomap_urls")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            text=draw_survey_map,
            filename="survey_locations_ecomap.html",
            **(params_dict.get("persist_ov_ecomap_urls") or {}),
        )
        .call()
    )

    convt_pie_html_png = (
        html_to_png.validate()
        .set_task_instance_id("convt_pie_html_png")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            html_path=draw_survey_pies,
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            config={
                "full_page": False,
                "device_scale_factor": 2.0,
                "wait_for_timeout": 25,
                "max_concurrent_pages": 1,
            },
            **(params_dict.get("convt_pie_html_png") or {}),
        )
        .call()
    )

    convt_bar_html_png = (
        html_to_png.validate()
        .set_task_instance_id("convt_bar_html_png")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            html_path=draw_survey_bar,
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            config={
                "full_page": False,
                "device_scale_factor": 2.0,
                "wait_for_timeout": 25,
                "max_concurrent_pages": 1,
            },
            **(params_dict.get("convt_bar_html_png") or {}),
        )
        .call()
    )

    convt_stats_html_png = (
        html_to_png.validate()
        .set_task_instance_id("convt_stats_html_png")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            html_path=draw_stat_box,
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            config={
                "full_page": False,
                "device_scale_factor": 2.0,
                "wait_for_timeout": 25,
                "max_concurrent_pages": 1,
            },
            **(params_dict.get("convt_stats_html_png") or {}),
        )
        .call()
    )

    convt_ols_html_png = (
        html_to_png.validate()
        .set_task_instance_id("convt_ols_html_png")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            html_path=draw_ols_plots,
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            config={
                "full_page": False,
                "device_scale_factor": 2.0,
                "wait_for_timeout": 25,
                "max_concurrent_pages": 1,
            },
            **(params_dict.get("convt_ols_html_png") or {}),
        )
        .call()
    )

    convt_tuk_html_png = (
        html_to_png.validate()
        .set_task_instance_id("convt_tuk_html_png")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            html_path=draw_tukey_plots,
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            config={
                "full_page": False,
                "device_scale_factor": 2.0,
                "wait_for_timeout": 25,
                "max_concurrent_pages": 1,
            },
            **(params_dict.get("convt_tuk_html_png") or {}),
        )
        .call()
    )

    convt_likert_png = (
        html_to_png.validate()
        .set_task_instance_id("convt_likert_png")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            html_path=[persist_likert, persist_likert_eff],
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            config={
                "full_page": False,
                "device_scale_factor": 2.0,
                "wait_for_timeout": 25,
                "max_concurrent_pages": 1,
            },
            **(params_dict.get("convt_likert_png") or {}),
        )
        .call()
    )

    convt_attitude_png = (
        html_to_png.validate()
        .set_task_instance_id("convt_attitude_png")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            html_path=persist_att_ecomap_urls,
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            config={
                "full_page": False,
                "device_scale_factor": 2.0,
                "wait_for_timeout": 40000,
                "max_concurrent_pages": 1,
            },
            **(params_dict.get("convt_attitude_png") or {}),
        )
        .call()
    )

    convt_gender_png = (
        html_to_png.validate()
        .set_task_instance_id("convt_gender_png")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            html_path=persist_gn_ecomap_urls,
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            config={
                "full_page": False,
                "device_scale_factor": 2.0,
                "wait_for_timeout": 40000,
                "max_concurrent_pages": 1,
            },
            **(params_dict.get("convt_gender_png") or {}),
        )
        .call()
    )

    convt_overall_png = (
        html_to_png.validate()
        .set_task_instance_id("convt_overall_png")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            html_path=persist_ov_ecomap_urls,
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            config={
                "full_page": False,
                "device_scale_factor": 2.0,
                "wait_for_timeout": 40000,
                "max_concurrent_pages": 1,
            },
            **(params_dict.get("convt_overall_png") or {}),
        )
        .call()
    )

    persist_survey_context = (
        persist_survey_word.validate()
        .set_task_instance_id("persist_survey_context")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            template_path=download_ate_tpt,
            output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            time_period=time_range,
            box_h_cm=6.5,
            box_w_cm=11.11,
            filename="social_survey.docx",
            demographic_csv="demographic_table.csv",
            **(params_dict.get("persist_survey_context") or {}),
        )
        .call()
    )

    survey_dashboard = (
        gather_dashboard.validate()
        .set_task_instance_id("survey_dashboard")
        .handle_errors()
        .with_tracing()
        .skipif(
            conditions=[
                any_is_empty_df,
                any_dependency_skipped,
            ],
            unpack_depth=1,
        )
        .partial(
            details=workflow_details,
            widgets=[],
            time_range=time_range,
            groupers=groupers,
            **(params_dict.get("survey_dashboard") or {}),
        )
        .call()
    )

    return survey_dashboard
